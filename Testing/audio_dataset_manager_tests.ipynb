{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working page leafthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def paginate(page, max_page, page_change):\n",
    "    new_page = page + page_change\n",
    "    new_page = max(1, new_page)  # Ensures page is not less than 1\n",
    "    new_page = min(new_page, max_page)  # Ensures page does not exceed max_page\n",
    "    return new_page\n",
    "\n",
    "def paginate_go(page, max_page):\n",
    "    try:\n",
    "        page = int(page)\n",
    "    except ValueError:\n",
    "        print(f'Invalid page number: {page}')\n",
    "        return None\n",
    "    return paginate(page, max_page, 0)\n",
    "def create_gradio_app():\n",
    "    with gr.Blocks() as app:\n",
    "        with gr.Row():\n",
    "            page_input = gr.Number(label=\"Page Number\", value=1)\n",
    "            max_page = gr.Number(label=\"Max Page\", value=10)  # Assuming max 10 pages for testing\n",
    "            go_button = gr.Button(\"Go to Page\")\n",
    "            next_button = gr.Button(\"Next\")\n",
    "            prev_button = gr.Button(\"Previous\")\n",
    "            current_page_label = gr.Label(\"Current Page: 1\")\n",
    "\n",
    "        def update_page_label(page):\n",
    "            current_page_label.update(f\"Current Page: {page}\")\n",
    "\n",
    "        go_button.click(fn=paginate_go, inputs=[page_input, max_page], outputs=page_input)\n",
    "        next_button.click(fn=lambda x, y: paginate(x, y, 1), inputs=[page_input, max_page], outputs=page_input)\n",
    "        prev_button.click(fn=lambda x, y: paginate(x, y, -1), inputs=[page_input, max_page], outputs=page_input)\n",
    "        page_input.change(update_page_label)\n",
    "\n",
    "    return app\n",
    "\n",
    "app = create_gradio_app()\n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working going through images across different pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import math\n",
    "import os\n",
    "\n",
    "IMAGES_TO_SHOW = 1  # Set to 1 since we're showing one audio file per page\n",
    "loaded_audios = []  # Global variable to store the loaded audios\n",
    "\n",
    "def paginate(page, max_page, page_change):\n",
    "    new_page = page + page_change\n",
    "    new_page = max(1, new_page)\n",
    "    new_page = min(new_page, max_page)\n",
    "    return new_page\n",
    "\n",
    "def get_audio_for_page(all_audios, page):\n",
    "    if 1 <= page <= len(all_audios):\n",
    "        return all_audios[page - 1]\n",
    "    return None  # Return None if the page is out of range\n",
    "\n",
    "def update_audio_display(page):\n",
    "    global loaded_audios\n",
    "    max_page = math.ceil(len(loaded_audios) / IMAGES_TO_SHOW)\n",
    "    displayed_audio = get_audio_for_page(loaded_audios, page)\n",
    "    audio_name = os.path.basename(displayed_audio) if displayed_audio else \"\"\n",
    "    current_page_label_text = f\"Current Page: {page}/{max_page}\"\n",
    "    return displayed_audio, audio_name, page, current_page_label_text\n",
    "\n",
    "def handle_pagination(page, delta):\n",
    "    global loaded_audios\n",
    "    max_page = math.ceil(len(loaded_audios) / IMAGES_TO_SHOW)\n",
    "    new_page = paginate(page, max_page, delta)\n",
    "    return update_audio_display(new_page)\n",
    "\n",
    "def handle_audio_load(audios):\n",
    "    global loaded_audios\n",
    "    loaded_audios = audios\n",
    "    return update_audio_display(1)  # Display first audio\n",
    "\n",
    "def create_gradio_app():\n",
    "    with gr.Blocks() as app:\n",
    "        with gr.Row():\n",
    "            audio_loader = gr.File(label=\"Load Audio Files\", file_count='multiple')\n",
    "            audio_player = gr.Audio(label=\"Audio Player\")\n",
    "            audio_name_box = gr.Textbox(label=\"Audio File Name\", interactive=True)\n",
    "\n",
    "        with gr.Row():\n",
    "            page_input = gr.Number(label=\"Page Number\", value=1, visible=True)\n",
    "            current_page_label = gr.Label(\"Current Page: 1/X\")\n",
    "            go_button = gr.Button(\"Go to Page\")\n",
    "            prev_button = gr.Button(\"Previous\")\n",
    "            next_button = gr.Button(\"Next\")\n",
    "\n",
    "        audio_loader.change(fn=handle_audio_load, inputs=[audio_loader], outputs=[audio_player, audio_name_box, page_input, current_page_label])\n",
    "        next_button.click(fn=lambda page: handle_pagination(page, 1), inputs=[page_input], outputs=[audio_player, audio_name_box, page_input, current_page_label])\n",
    "        prev_button.click(fn=lambda page: handle_pagination(page, -1), inputs=[page_input], outputs=[audio_player, audio_name_box, page_input, current_page_label])\n",
    "        go_button.click(fn=lambda page: update_audio_display(page), inputs=[page_input], outputs=[audio_player, audio_name_box, page_input, current_page_label])\n",
    "\n",
    "    return app\n",
    "\n",
    "app = create_gradio_app()\n",
    "app.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display audio files per page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import math\n",
    "import os\n",
    "\n",
    "IMAGES_TO_SHOW = 1  # Set to 1 since we're showing one audio file per page\n",
    "loaded_audios = []  # Global variable to store the loaded audios\n",
    "\n",
    "def paginate(page, max_page, page_change):\n",
    "    new_page = page + page_change\n",
    "    new_page = max(1, new_page)\n",
    "    new_page = min(new_page, max_page)\n",
    "    return new_page\n",
    "\n",
    "def get_audio_for_page(all_audios, page):\n",
    "    if 1 <= page <= len(all_audios):\n",
    "        return all_audios[page - 1]\n",
    "    return None  # Return None if the page is out of range\n",
    "\n",
    "def update_audio_display(page):\n",
    "    global loaded_audios\n",
    "    max_page = math.ceil(len(loaded_audios) / IMAGES_TO_SHOW)\n",
    "    displayed_audio = get_audio_for_page(loaded_audios, page)\n",
    "    audio_name = os.path.basename(displayed_audio) if displayed_audio else \"\"\n",
    "    current_page_label_text = f\"Current Page: {page}/{max_page}\"\n",
    "    return displayed_audio, audio_name, page, current_page_label_text\n",
    "\n",
    "def handle_pagination(page, delta):\n",
    "    global loaded_audios\n",
    "    max_page = math.ceil(len(loaded_audios) / IMAGES_TO_SHOW)\n",
    "    new_page = paginate(page, max_page, delta)\n",
    "    return update_audio_display(new_page)\n",
    "\n",
    "def handle_audio_load(audios):\n",
    "    global loaded_audios\n",
    "    loaded_audios = audios\n",
    "    return update_audio_display(1)  # Display first audio\n",
    "\n",
    "def create_gradio_app():\n",
    "    with gr.Blocks() as app:\n",
    "        with gr.Row():\n",
    "            audio_loader = gr.File(label=\"Load Audio Files\", file_count='multiple')\n",
    "            audio_player = gr.Audio(label=\"Audio Player\")\n",
    "            audio_name_box = gr.Textbox(label=\"Audio File Name\", interactive=True)\n",
    "\n",
    "        with gr.Row():\n",
    "            page_input = gr.Number(label=\"Page Number\", value=1, visible=True)\n",
    "            current_page_label = gr.Label(\"Current Page: 1/X\")\n",
    "            go_button = gr.Button(\"Go to Page\")\n",
    "            prev_button = gr.Button(\"Previous\")\n",
    "            next_button = gr.Button(\"Next\")\n",
    "\n",
    "        audio_loader.change(fn=handle_audio_load, inputs=[audio_loader], outputs=[audio_player, audio_name_box, page_input, current_page_label])\n",
    "        next_button.click(fn=lambda page: handle_pagination(page, 1), inputs=[page_input], outputs=[audio_player, audio_name_box, page_input, current_page_label])\n",
    "        prev_button.click(fn=lambda page: handle_pagination(page, -1), inputs=[page_input], outputs=[audio_player, audio_name_box, page_input, current_page_label])\n",
    "        go_button.click(fn=lambda page: update_audio_display(page), inputs=[page_input], outputs=[audio_player, audio_name_box, page_input, current_page_label])\n",
    "\n",
    "    return app\n",
    "\n",
    "app = create_gradio_app()\n",
    "app.launch()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplified script for managing one audio per page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "\n",
    "def create_gradio_app():\n",
    "    loaded_audios = []  # Stores the loaded audio files\n",
    "\n",
    "    def change_audio(index):\n",
    "        if 0 <= index < len(loaded_audios):\n",
    "            audio_file = loaded_audios[index]\n",
    "            audio_name = os.path.basename(audio_file)\n",
    "            current_page_label = f\"Current Audio: {index + 1}/{len(loaded_audios)}\"\n",
    "            return audio_file, audio_name, index + 1, current_page_label\n",
    "        return None, \"\", 1, \"Audio not available\"\n",
    "\n",
    "    def next_audio(index):\n",
    "        return change_audio(index)\n",
    "\n",
    "    def prev_audio(index):\n",
    "        return change_audio(index - 2)\n",
    "\n",
    "    def load_audios(audios):\n",
    "        nonlocal loaded_audios\n",
    "        loaded_audios = audios\n",
    "        return change_audio(0)\n",
    "\n",
    "    with gr.Blocks() as app:\n",
    "        audio_loader = gr.File(label=\"Load Audio Files\", file_count='multiple')\n",
    "        audio_player = gr.Audio(label=\"Audio Player\")\n",
    "        audio_name_box = gr.Textbox(label=\"Audio File Name\", interactive=True)\n",
    "        page_input = gr.Number(label=\"Go to page:\", value=1, visible=True)\n",
    "        current_page_label = gr.Label(\"Current Audio: 1/X\")\n",
    "        next_button = gr.Button(\"Next\")\n",
    "        prev_button = gr.Button(\"Previous\")\n",
    "        go_button = gr.Button(\"Go to Page\")\n",
    "\n",
    "        audio_loader.change(fn=load_audios, inputs=[audio_loader], outputs=[audio_player, audio_name_box, page_input, current_page_label])\n",
    "        next_button.click(fn=lambda index: next_audio(index), inputs=[page_input], outputs=[audio_player, audio_name_box, page_input, current_page_label])\n",
    "        prev_button.click(fn=lambda index: prev_audio(index), inputs=[page_input], outputs=[audio_player, audio_name_box, page_input, current_page_label])\n",
    "        go_button.click(fn=lambda index: change_audio(index - 1), inputs=[page_input], outputs=[audio_player, audio_name_box, page_input, current_page_label])\n",
    "\n",
    "    return app\n",
    "\n",
    "app = create_gradio_app()\n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs and Outputs in Gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics of inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def change_textbox2():\n",
    "    return 'So what does a fine person like you do in a place such as this?'\n",
    "\n",
    "def change_textbox3():\n",
    "    return 'Yeah, I know. I love coding so much that I am still there at 10PM doing stuff like this instead of playing Elden Ring.'\n",
    "\n",
    "# The function change textboxes() is the function called by the go_button from the interface. The function itself can call other functions which will themselves\n",
    "# send variables or new components that we can then return to the UI. \n",
    "\n",
    "def change_textboxes(initial_text):\n",
    "    text1 = f'Oh so your name is {initial_text}! Nice to meet you!'\n",
    "    text2 = change_textbox2()\n",
    "    text3 = change_textbox3()\n",
    "\n",
    "    return text1, text2, text3\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    textbox1 = gr.Textbox(label='What is your name?')\n",
    "    textbox2 = gr.Textbox()\n",
    "    textbox3 = gr.Textbox()\n",
    "    go_button = gr.Button('Do your magic')\n",
    "    go_button.click(fn=change_textboxes, inputs=[textbox1], outputs=[textbox1, textbox2, textbox3])\n",
    "\n",
    "\n",
    "demo.launch()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the visibility of components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function that you call through a button can also send new gradio components that will automatically get mapped to the outputs defined in the UI (go_button.click), and thus replace them / update them. That is how you change the visibility of an element in Gradio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def change_textboxes(initial_text):\n",
    "    text1 = f'Oh so your name is {initial_text}! Nice to meet you!'\n",
    "    # Check if the user has entered a name\n",
    "    if initial_text.strip():\n",
    "        # Return visible textboxes with the respective messages\n",
    "        textbox2 = gr.Textbox(value='So what does a fine person like you do in a place such as this?', visible=True)\n",
    "        textbox3 = gr.Textbox(value='Yeah, I know. I love coding so much that I am still there at 10PM doing stuff like this instead of playing Elden Ring.', visible=True)\n",
    "    else:\n",
    "        # Return invisible textboxes\n",
    "        textbox2 = gr.Textbox(value='', visible=False)\n",
    "        textbox3 = gr.Textbox(value='', visible=False)\n",
    "    return text1, textbox2, textbox3\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    textbox1 = gr.Textbox(label='What is your name?')\n",
    "    go_button = gr.Button('Do your magic')\n",
    "\n",
    "    textbox2 = gr.Textbox(visible=False)  # Initially not visible\n",
    "    textbox3 = gr.Textbox(visible=False)  # Initially not visible\n",
    "\n",
    "    go_button.click(fn=change_textboxes, inputs=textbox1, outputs=[textbox1, textbox2, textbox3])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whisper and transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import json\n",
    "import os\n",
    "import torchaudio\n",
    "\n",
    "\n",
    "def transcribe_audio(audio_path, whisper_model):\n",
    "    audio_name = os.path.splitext(audio_path)[0]\n",
    "    model = whisper.load_model(whisper_model)\n",
    "    result = model.transcribe(audio_path)\n",
    "    return {audio_name: result}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "whisper_model = 'medium.en'\n",
    "audio_file =  r\"/home/maelys/AI_PROJECTS/SOUND/TOOLS/MRQ/ai-voice-cloning/training/train_mark_ultimate_8600/audio/But�_our_paths_soon_diverged_2_blood_guzzling.wav\"\n",
    "\n",
    "transcription = transcribe_audio(audio_file, whisper_model)\n",
    "\n",
    "json_file_path = \"json_test.json\"\n",
    "json_object = json.dumps(transcription, indent=4)\n",
    "\n",
    "with open (json_file_path, \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems I don't get exactly the same tokens or values as the MRQ ai-voice-cloning tool, although they are close. However, as I'm primarily building this tool to help me prepare datasets that I then will feed MRQ's tool, I find it hazardous to take the risk to botch the transcription of like thousands and thousand of audios, only to be compelled to do everything again in a few months. What I'm gonna do, then, is give a choice to the user of my tool. In the transcription tab, there will be a choice \"Transcribe here\" will launch and realize the transcribing internally with my tool. \"Transcribe with MRQ\" will make a textbox appear, describing the exact process to transcribe the audios through MRQ's tool, and then invite the user to go to the transcription check tab. In this last tab, the user will then simply point to the folder where the whisper.json has been created, whether internally or through MRQ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trasncribe panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import whisper\n",
    "import json\n",
    "\n",
    "def transcribe_audios(input, model, export_folder):\n",
    "    model = whisper.load_model(model)\n",
    "    export_path = os.path.join(export_folder, 'whisper.json')\n",
    "    \n",
    "    transcriptions = {}\n",
    "\n",
    "    for audio in os.listdir(input):\n",
    "        audio_path = os.path.join(input, audio)\n",
    "        audio_name = os.path.splitext(audio)[0]\n",
    "        \n",
    "        result = model.transcribe(audio_path)\n",
    "\n",
    "        # Add to the transcriptions dictionary\n",
    "        transcriptions[audio] = result\n",
    "\n",
    "    # Write to a JSON file\n",
    "    with open(export_path, 'w') as json_file:\n",
    "        json.dump(transcriptions, json_file, indent=4)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def internal_transcriber(input, model, export_path):\n",
    "    transcribe_audios(input, model, export_path)\n",
    "    markdown_text = f\"\"\"\n",
    "    \n",
    "        >> Your audios have been retranscribed in **{export_path}**\n",
    "\n",
    "    \"\"\"\n",
    "    return gr.Markdown(value=markdown_text, visible=True)\n",
    "\n",
    "def choose_transcriber(transcriber_choice):\n",
    "    if transcriber_choice == 'This tool':\n",
    "        internal_transcriber_group = gr.Group(visible=True)\n",
    "        mrq_tool_group = gr.Group(visible=False)\n",
    "    \n",
    "    else:\n",
    "        internal_transcriber_group = gr.Group(visible=False)\n",
    "        mrq_tool_group = gr.Group(visible=True)\n",
    "    \n",
    "    return internal_transcriber_group, mrq_tool_group\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    choice_radio = gr.Radio(label='Which tool do you want to use for transcribing?', choices=['This tool', 'MRQ ai-voice-cloning'])\n",
    "\n",
    "   \n",
    "    internal_transcriber_group = gr.Group(visible=False)\n",
    "    mrq_tool_group = gr.Group(visible=False)\n",
    "\n",
    "\n",
    "    with internal_transcriber_group:\n",
    "        input_folder = gr.Textbox(label='Path to the folder you want to transcribe')\n",
    "        model_choice = gr.Dropdown(label='Which Whisper model do you want to use?', \n",
    "                                            choices=[\"tiny\", \"tiny.en\", \"base\", \"base.en\", \"small\", \"small.en\", \n",
    "                                                    \"medium\", \"medium.en\",\n",
    "                                                    \"large\", \"large-v1\", \"large-v2\", ])\n",
    "        export_path = gr.Textbox(label='Path to the folder you want to export your transcribed json')\n",
    "        info_textbox = gr.Markdown(visible=False)\n",
    "        submit_button = gr.Button('Transcribe')\n",
    "    \n",
    "    with mrq_tool_group:\n",
    "        instructions_text = \"\"\"\n",
    "      \n",
    "                ># Hey there!\n",
    "     \n",
    "                >So you chose to use MRQ's ai-voice-cloning tool for your retranscription! Good choice, that tool is pure magic.\n",
    "\n",
    "                >Here's how to do this:\n",
    "\n",
    "                >>1. Go to MRQ ai-voice-cloning repo: [MRQ ai-voice-cloning](https://git.ecker.tech/mrq/ai-voice-cloning)\n",
    "                2. Clone the repo, install the tool (you have all instructions on the git page)\n",
    "                3. Put the voices you want to transcribe in a dedicated folder, inside the \"voices\" folder\n",
    "                4. Launch the interface (start.bat or start.sh depending on your OS)\n",
    "                5. Go to the \"Training\" tab\n",
    "                6. Choose your voice in \"Dataset Source\"\n",
    "                7. Click on Transcribe and Process\n",
    "                8. The \"whisper.json\" is written in the \"training\" folder, so go get the path\n",
    "                9. You're ready to go to the \"Checkout Transcription Tab\" here, point to the \"whisper.json\" file produced by MRQ ai-voice-cloning tool!\n",
    "                \n",
    "    \"\"\"\n",
    "        \n",
    "\n",
    "        \n",
    "        mrq_textbox = gr.Markdown(value = instructions_text)\n",
    "\n",
    "\n",
    "    choice_radio.change(fn=choose_transcriber, inputs=[choice_radio], outputs=[internal_transcriber_group, mrq_tool_group])\n",
    "    submit_button.click(fn=internal_transcriber, inputs=[input_folder, model_choice, export_path], outputs=[info_textbox])\n",
    "    \n",
    "\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "my_path = \"/home/maelys/AI_PROJECTS/SOUND/TOOLS/MRQ/ai-voice-cloning/training/train_mark_ultimate_8600/audio/Buté_our_paths_soon_diverged_2_blood_guzzling.wav\"\n",
    "\n",
    "# Split the path and the filename\n",
    "path_components = os.path.split(my_path)\n",
    "\n",
    "# Extract the filename\n",
    "filename_with_extension = path_components[1]\n",
    "\n",
    "# Split the filename and the extension\n",
    "filename_without_extension, _ = os.path.splitext(filename_with_extension)\n",
    "\n",
    "print(filename_without_extension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with json manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic json display "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def get_text(audio_folder, json_file):\n",
    "    extensions = ['.mp3', '.wav']\n",
    "    audios = [audio for audio in os.listdir(audio_folder) if os.path.splitext(audio)[1] in extensions]\n",
    "    with open(json_file, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "\n",
    "    print ([json_data[audio]['text'] for audio in audios])\n",
    "    return [json_data[audio]['text'] for audio in audios]\n",
    "\n",
    "\n",
    "audio_folder = r'/home/maelys/AI_PROJECTS/SOUND/DATA_CENTER/Tests/'\n",
    "json_file = r'/home/maelys/AI_PROJECTS/SOUND/DATA_CENTER/Tests/whisper.json'\n",
    "\n",
    "\n",
    "if texts := get_text(audio_folder, json_file):\n",
    "    print('ok')\n",
    "    # for text in texts:\n",
    "    #     print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change json interactively (stuck here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "\n",
    "def change_json(json_file, audio_folder, json_textbox):\n",
    "    with open(json_file, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "    \n",
    "    extensions = ['.mp3', '.wav']\n",
    "    audios = [audio for audio in os.listdir(audio_folder) if os.path.splitext(audio)[1] in extensions]\n",
    "\n",
    "    # Flag to track if any changes were made\n",
    "    changes_made = False\n",
    "\n",
    "    for audio in audios:\n",
    "        if audio in json_data:\n",
    "            # Update the text for the audio file using the value from json_textbox\n",
    "            json_data[audio]['text'] = json_textbox[audio]\n",
    "            changes_made = True\n",
    "\n",
    "    # Write the updated JSON back to the file, if any changes were made\n",
    "    if changes_made:\n",
    "        with open(json_file, 'w') as file:\n",
    "            json.dump(json_data, file, indent=4) # Adding indentation for readability\n",
    "    \n",
    "    return 'Update complete' if changes_made else 'No changes made'\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def load_stuff(json_file, audio_folder):\n",
    "    with open(json_file, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "    \n",
    "    extensions = ['.mp3', '.wav']\n",
    "    audios = [audio for audio in os.listdir(audio_folder) if os.path.splitext(audio)[1] in extensions]\n",
    "    with open(json_file, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "\n",
    "    texts = [json_data[audio]['text'] for audio in audios] # Faut comprendre pourquoi si on return direct ça ça le met dans une liste\n",
    "\n",
    "    return texts[0]\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    json_file = gr.File(label='json file')\n",
    "    audio_folder = gr.Textbox(label='audios') # We have to keep loading a path instead of an audio, because Gradio changes the names of the audio it loads when using gr.File... It deletes the commas etc, which we have in our titles. Thus the json can't find the key.\n",
    "    json_textbox = gr.Textbox(interactive=True)\n",
    "    \n",
    "    submit_btn = gr.Button('Submit')\n",
    "    save_json = gr.Button('Save Json')\n",
    "    console_output = gr.Textbox()\n",
    "    \n",
    "\n",
    "\n",
    "    submit_btn.click(fn=load_stuff, inputs = [json_file, audio_folder], outputs = [json_textbox])\n",
    "    save_json.click(fn=change_json, inputs = [json_file, audio_folder, json_textbox], outputs=[console_output])\n",
    "\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate box rows dynamically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "[textbox] is not a callable object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 44\u001b[0m\n\u001b[1;32m     40\u001b[0m     textboxes \u001b[38;5;241m=\u001b[39m [textbox1, textbox2, textbox3, textbox4, textbox5, textbox6, textbox7, textbox8, textbox9, textbox10]\n\u001b[1;32m     42\u001b[0m     show_btn \u001b[38;5;241m=\u001b[39m gr\u001b[38;5;241m.\u001b[39mButton(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mShow\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m     \u001b[43mshow_btn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclick\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_stuff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtextboxes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtextboxes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m demo\u001b[38;5;241m.\u001b[39mlaunch()\n",
      "File \u001b[0;32m~/anaconda3/envs/audio-dataset-manager/lib/python3.9/site-packages/gradio/events.py:280\u001b[0m, in \u001b[0;36mEventListener._setup.<locals>.event_trigger\u001b[0;34m(block, fn, inputs, outputs, api_name, scroll_to_output, show_progress, queue, batch, max_batch_size, preprocess, postprocess, cancels, every, trigger_mode, js, concurrency_limit, concurrency_id, show_api)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Context\u001b[38;5;241m.\u001b[39mroot_block \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_event_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m outside of a gradio.Blocks context.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m     )\n\u001b[0;32m--> 280\u001b[0m dep, dep_index \u001b[38;5;241m=\u001b[39m \u001b[43mContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot_block\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_event_trigger\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mEventListenerMethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_has_trigger\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_event_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpostprocess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpostprocess\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscroll_to_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscroll_to_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconcurrency_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcurrency_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconcurrency_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcurrency_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mqueue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqueue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrigger_after\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_trigger_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrigger_only_on_success\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_trigger_only_on_success\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrigger_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrigger_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_api\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_api\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m set_cancel_events(\n\u001b[1;32m    303\u001b[0m     [EventListenerMethod(block \u001b[38;5;28;01mif\u001b[39;00m _has_trigger \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, _event_name)],\n\u001b[1;32m    304\u001b[0m     cancels,\n\u001b[1;32m    305\u001b[0m )\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _callback:\n",
      "File \u001b[0;32m~/anaconda3/envs/audio-dataset-manager/lib/python3.9/site-packages/gradio/blocks.py:886\u001b[0m, in \u001b[0;36mBlocks.set_event_trigger\u001b[0;34m(self, targets, fn, inputs, outputs, preprocess, postprocess, scroll_to_output, show_progress, api_name, js, no_target, queue, batch, max_batch_size, cancels, every, collects_event_data, trigger_after, trigger_only_on_success, trigger_mode, concurrency_limit, concurrency_id, show_api)\u001b[0m\n\u001b[1;32m    883\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m [outputs]\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cancels:\n\u001b[0;32m--> 886\u001b[0m     \u001b[43mcheck_function_inputs_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_as_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m every \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m every \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    888\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter every must be positive or None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/audio-dataset-manager/lib/python3.9/site-packages/gradio/utils.py:820\u001b[0m, in \u001b[0;36mcheck_function_inputs_match\u001b[0;34m(fn, inputs, inputs_as_dict)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Checks if parameter has a type hint designating it as a gr.Request, gr.EventData, gr.OAuthProfile or gr.OAuthToken.\"\"\"\u001b[39;00m\n\u001b[1;32m    819\u001b[0m hint \u001b[38;5;241m=\u001b[39m parameter_types\u001b[38;5;241m.\u001b[39mget(name)\n\u001b[0;32m--> 820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m hint:\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    822\u001b[0m is_request \u001b[38;5;241m=\u001b[39m hint \u001b[38;5;241m==\u001b[39m Request\n",
      "File \u001b[0;32m~/anaconda3/envs/audio-dataset-manager/lib/python3.9/inspect.py:3118\u001b[0m, in \u001b[0;36msignature\u001b[0;34m(obj, follow_wrapped)\u001b[0m\n\u001b[1;32m   3116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msignature\u001b[39m(obj, \u001b[38;5;241m*\u001b[39m, follow_wrapped\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   3117\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_wrapped\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/audio-dataset-manager/lib/python3.9/inspect.py:2867\u001b[0m, in \u001b[0;36mSignature.from_callable\u001b[0;34m(cls, obj, follow_wrapped)\u001b[0m\n\u001b[1;32m   2864\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   2865\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_callable\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj, \u001b[38;5;241m*\u001b[39m, follow_wrapped\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   2866\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2867\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_signature_from_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigcls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2868\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mfollow_wrapper_chains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/audio-dataset-manager/lib/python3.9/inspect.py:2242\u001b[0m, in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[1;32m   2237\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Private helper function to get signature for arbitrary\u001b[39;00m\n\u001b[1;32m   2238\u001b[0m \u001b[38;5;124;03mcallable objects.\u001b[39;00m\n\u001b[1;32m   2239\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(obj):\n\u001b[0;32m-> 2242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m is not a callable object\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj))\n\u001b[1;32m   2244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, types\u001b[38;5;241m.\u001b[39mMethodType):\n\u001b[1;32m   2245\u001b[0m     \u001b[38;5;66;03m# In this case we skip the first parameter of the underlying\u001b[39;00m\n\u001b[1;32m   2246\u001b[0m     \u001b[38;5;66;03m# function (usually `self` or `cls`).\u001b[39;00m\n\u001b[1;32m   2247\u001b[0m     sig \u001b[38;5;241m=\u001b[39m _signature_from_callable(\n\u001b[1;32m   2248\u001b[0m         obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m,\n\u001b[1;32m   2249\u001b[0m         follow_wrapper_chains\u001b[38;5;241m=\u001b[39mfollow_wrapper_chains,\n\u001b[1;32m   2250\u001b[0m         skip_bound_arg\u001b[38;5;241m=\u001b[39mskip_bound_arg,\n\u001b[1;32m   2251\u001b[0m         sigcls\u001b[38;5;241m=\u001b[39msigcls)\n",
      "\u001b[0;31mTypeError\u001b[0m: [textbox] is not a callable object"
     ]
    }
   ],
   "source": [
    "import gradio as gr \n",
    "\n",
    "def show_stuff(*args):\n",
    "    textboxes = args\n",
    "    new_textboxes = []\n",
    "    # Iterate through the original list of textboxes to create new ones based on the visibility condition.\n",
    "    for i in range (0, len(textboxes)):\n",
    "        # If i is less than or equal to 5, the textbox is visible. Otherwise, it's invisible.\n",
    "        if i <= 5:\n",
    "            new_textbox = gr.Textbox(visible=True, value=str(i))  # Ensuring value is a string\n",
    "        else:\n",
    "            new_textbox = gr.Textbox(visible=False, value=str(i))  # Ensuring value is a string\n",
    "        \n",
    "        new_textboxes.append(new_textbox)\n",
    "\n",
    "    return new_textboxes\n",
    "        \n",
    "\n",
    "def show_one(textbox):\n",
    "    print(type(textbox))\n",
    "    return gr.Textbox(visible=True, value='coucou')\n",
    "    \n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "\n",
    "    \n",
    "    textbox1 = gr.Textbox(visible=False)\n",
    "    textbox2 = gr.Textbox(visible=False)\n",
    "    textbox3 = gr.Textbox(visible=False)\n",
    "    textbox4 = gr.Textbox(visible=False)\n",
    "    textbox5 = gr.Textbox(visible=False)\n",
    "    textbox6 = gr.Textbox(visible=False)\n",
    "    textbox7 = gr.Textbox(visible=False)\n",
    "    textbox8 = gr.Textbox(visible=False)\n",
    "    textbox9 = gr.Textbox(visible=False)\n",
    "    textbox10 = gr.Textbox(visible=False)\n",
    "\n",
    "    #amount_to_show = gr.Number(label='Amount ot boxes to show')\n",
    "\n",
    "    textboxes = [textbox1, textbox2, textbox3, textbox4, textbox5, textbox6, textbox7, textbox8, textbox9, textbox10]\n",
    "    \n",
    "    show_btn = gr.Button('Show')\n",
    "\n",
    "    show_btn.click(fn=show_stuff, inputs=textboxes, outputs=textboxes)\n",
    "\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drafting the checkout tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "def create_interface():\n",
    "    loaded_audios = []\n",
    "\n",
    "    def change_audio(index):\n",
    "        if 0 <= index < len(loaded_audios):\n",
    "            audio_file = loaded_audios[index]\n",
    "            audio_name = os.path.basename(audio_file)\n",
    "            current_page_label_label = f\"Current Audio: {index + 1}/{len(loaded_audios)}\"\n",
    "            return audio_file, audio_name, index + 1, current_page_label_label\n",
    "        return None, \"\", 1, \"Audio not available\"\n",
    "\n",
    "    def handle_pagination(page, delta):\n",
    "        new_index = page -1 + delta # We asjust for zero-based indexing, and the delta determines which way we move\n",
    "        return change_audio(new_index)\n",
    "\n",
    "\n",
    "    def load_audios(audio_path, json_file, epub_file):\n",
    "        nonlocal loaded_audios\n",
    "        extensions = ['.mp3', '.wav']\n",
    "        for audio in os.listdir(audio_path):\n",
    "            name, extension = os.path.splitext(audio)\n",
    "            filepath = os.path.join(audio_path, audio)\n",
    "            if extension in extensions:      \n",
    "                loaded_audios.append(filepath)\n",
    "        \n",
    "        return change_audio(0)\n",
    "\n",
    "\n",
    "    with gr.Blocks() as interface:\n",
    "        audios = gr.Textbox(label='Write the folder to your audios')\n",
    "        json_file = gr.File(label='Your whisper.json')\n",
    "        ebook_file = gr.File(label='Your epub or ebook for reference (Optional)')\n",
    "        submit_button = gr.Button('Load') # This is supposed to load the audios, but also the json file and the ebook if they exist\n",
    "        \n",
    "\n",
    "        process_group = gr.Group(visible=True)\n",
    "\n",
    "        with process_group:\n",
    "            with gr.Row():\n",
    "                audio_player = gr.Audio()\n",
    "                audio_name_box = gr.Textbox(label='Audio File Name', interactive=True)\n",
    "                \n",
    "\n",
    "            with gr.Row():\n",
    "                previous_audio_btn = gr.Button('Previous')\n",
    "                delete_audio = gr.Button('Delete from dataset')\n",
    "                next_audio_btn = gr.Button('Next')\n",
    "\n",
    "            with gr.Row(equal_height=True):\n",
    "                \n",
    "                json_reference = gr.Textbox(scale=20, interactive=True)\n",
    "                save_json_button = gr.Button('Save JSON')\n",
    "                    \n",
    "            with gr.Row():\n",
    "                epub_reference = gr.Textbox()\n",
    "            \n",
    "\n",
    "            current_page_label = gr.Label('Current page : 1/X')\n",
    "            page_input = gr.Number(label='Enter page', value=1)\n",
    "            go_button = gr.Button('Go to page')\n",
    "\n",
    "            submit_button.click(fn=load_audios, inputs = [audios, json_file, ebook_file], outputs = [audio_player, audio_name_box, page_input, current_page_label] ) \n",
    "            next_audio_btn.click(fn=lambda index: handle_pagination(index, 1), inputs=[page_input], outputs=[audio_player, audio_name_box, page_input, current_page_label])\n",
    "            previous_audio_btn.click(fn=lambda index: handle_pagination(index, -1), inputs=[page_input], outputs=[audio_player, audio_name_box, page_input, current_page_label])\n",
    "            go_button.click(fn=lambda index: change_audio(index - 1), inputs=[page_input], outputs=[audio_player, audio_name_box, page_input, current_page_label])\n",
    "\n",
    "    return interface\n",
    "\n",
    "\n",
    "app = create_interface()\n",
    "app.launch()\n",
    "    \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
