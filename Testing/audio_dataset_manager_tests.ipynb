{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import re\n",
    "import subprocess\n",
    "from pydub import AudioSegment\n",
    "from dataclasses import dataclass\n",
    "import os\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AudioProcess_Config():\n",
    "    \"\"\"Class to store the necessary variables to processing the audio\"\"\"\n",
    "    filepath: str\n",
    "    audio: any\n",
    "    input_format :str\n",
    "    export_format: str\n",
    "    output_format: str\n",
    "    output_folder: str\n",
    "    usable_folder: str\n",
    "    not_usable_folder: str\n",
    "    time_threshold: float\n",
    "    whisper_model: str\n",
    "    prefix : str\n",
    "    \n",
    "class AudioProcessor():\n",
    "    ''' Class to process the audios'''\n",
    "\n",
    "    def detect_silences(self, config, decibel=\"-23dB\"):\n",
    "        '''Function to detect silences in an audio'''\n",
    "\n",
    "        # Executing ffmpeg to detect silences\n",
    "        command = [\"ffmpeg\",\"-i\",config.filepath,\"-af\",f\"silencedetect=n={decibel}:d={str(config.time_threshold)}\",\"-f\",\"null\",\"-\"]\n",
    "        out = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n",
    "        stdout, stderr = out.communicate()\n",
    "\n",
    "        # Decoding and splitting ffmpeg output\n",
    "        output = stdout.decode(\"utf-8\")\n",
    "        silence_info = output.split('[silencedetect @')\n",
    "        silence_starts = []\n",
    "        silence_ends = []\n",
    "\n",
    "        if len(silence_info) <= 1:\n",
    "            return('No silence was detected')\n",
    "\n",
    "            # Process each detected silence fragment\n",
    "        for index, segment in enumerate(silence_info[1:], start=1):\n",
    "            segment_details = segment.split(']')[1]\n",
    "            if time_values := re.findall(r\"[-+]?\\d*\\.\\d+|\\d+\", segment_details):\n",
    "                time = float(time_values[0])\n",
    "\n",
    "                # Checking whether the time should be either the start or end time according to where we are in the iteration\n",
    "                if index % 2 == 0 :\n",
    "                    silence_ends.append(time)\n",
    "                else:\n",
    "                    silence_starts.append(time)\n",
    "\n",
    "        return list(zip(silence_starts, silence_ends))\n",
    "\n",
    "    def extract_midpoints(self, list):\n",
    "        ''' Function to extract the midpoints where the audio must be sliced '''\n",
    "        return [(start + end) / 2 for start, end in list]\n",
    "\n",
    "    def process_segment(self, config, start_point, end_point):\n",
    "        '''Extracts and exports a segment of the audio'''\n",
    "        segment = config.audio[start_point * 1000 : end_point * 1000]\n",
    "        temp_segment_name = f'temp_segment.{config.export_format}'\n",
    "        temp_segment_path = os.path.join(config.output_folder, 'temp', temp_segment_name)\n",
    "        segment.export(temp_segment_path, format=config.export_format)\n",
    "\n",
    "        return temp_segment_path, len(segment)\n",
    "\n",
    "\n",
    "def define_process_config(filepath, time_threshold, whisper_model, output_folder, prefix):\n",
    "    usable_folder = os.path.join(output_folder, 'Usable_Audios')\n",
    "    not_usable_folder = os.path.join(output_folder, 'Not_Usable_Audios')\n",
    "    input_format = filepath.split('.')[-1].lower()\n",
    "    audio = AudioSegment.from_file(filepath)\n",
    "\n",
    "    return AudioProcess_Config(\n",
    "        filepath=filepath,\n",
    "        audio=audio,\n",
    "        input_format=input_format,\n",
    "        export_format=input_format,\n",
    "        output_folder=output_folder,\n",
    "        usable_folder=usable_folder,\n",
    "        not_usable_folder=not_usable_folder,\n",
    "        time_threshold=time_threshold,\n",
    "        whisper_model=whisper_model,\n",
    "        prefix=prefix\n",
    "        \n",
    "    )\n",
    "    \n",
    "def main(filepath, time_threshold, whisper_model, output_folder, prefix=None):\n",
    "    process_config = define_process_config(filepath, time_threshold, whisper_model, output_folder, prefix)\n",
    "    ap = AudioProcessor()\n",
    "\n",
    "    if silence_list := ap.detect_silences(process_config):\n",
    "        midpoints = ap.extract_midpoints(silence_list)\n",
    "        start_point = 0\n",
    "        transcriptions_dict = {}\n",
    "\n",
    "        for end_point in midpoints:\n",
    "            segment_path, segment_length = ap.process_segment(process_config, start_point, end_point)\n",
    "\n",
    "        \n",
    "       \n",
    "    else:\n",
    "        print('no silences detected')\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7912\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7912/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maelys/anaconda3/envs/audio-dataset-manager/lib/python3.9/site-packages/gradio/processing_utils.py:345: UserWarning: Trying to convert audio automatically from int32 to 16-bit int format.\n",
      "  warnings.warn(warning.format(data.dtype))\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/maelys/anaconda3/envs/audio-dataset-manager/lib/python3.9/site-packages/gradio/queueing.py\", line 495, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "  File \"/home/maelys/anaconda3/envs/audio-dataset-manager/lib/python3.9/site-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/home/maelys/anaconda3/envs/audio-dataset-manager/lib/python3.9/site-packages/gradio/blocks.py\", line 1561, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/home/maelys/anaconda3/envs/audio-dataset-manager/lib/python3.9/site-packages/gradio/blocks.py\", line 1179, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"/home/maelys/anaconda3/envs/audio-dataset-manager/lib/python3.9/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/home/maelys/anaconda3/envs/audio-dataset-manager/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 2134, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/home/maelys/anaconda3/envs/audio-dataset-manager/lib/python3.9/site-packages/anyio/_backends/_asyncio.py\", line 851, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/home/maelys/anaconda3/envs/audio-dataset-manager/lib/python3.9/site-packages/gradio/utils.py\", line 678, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_118716/3488478403.py\", line 93, in main\n",
      "    process_config = define_process_config(filepath, time_threshold, whisper_model, output_folder, prefix)\n",
      "  File \"/tmp/ipykernel_118716/3488478403.py\", line 78, in define_process_config\n",
      "    return AudioProcess_Config(\n",
      "TypeError: __init__() missing 1 required positional argument: 'output_format'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "demo = gr.Interface(\n",
    "    fn=main,\n",
    "    inputs=[\n",
    "        gr.Audio(sources=\"upload\", \n",
    "                 type=\"filepath\"),\n",
    "        gr.Number(label = 'Time Threshold',\n",
    "                 info = 'Choose the approximate duration of a silence in the audio'), \n",
    "        gr.Dropdown(\n",
    "            [\n",
    "                \"Tiny\",\n",
    "                \"Base\",\n",
    "                \"Medium\",\n",
    "                \"Large\"\n",
    "            ],\n",
    "            label = \"Whisper model\",\n",
    "            info = \"Choose the Whisper model with which you want to do the retranscription\"\n",
    "        ),\n",
    "     \n",
    "          gr.Textbox(\n",
    "            label = 'Output Folder',\n",
    "            info = 'Type the path where you want to output the segmented audios)'\n",
    "        ),\n",
    "           gr.Textbox(\n",
    "            label = 'Prefix',\n",
    "            info = 'Choose a prefix for your extracted audio segments (like the name and chapter of the book)'\n",
    "        )\n",
    "        \n",
    "        \n",
    "    \n",
    "    ],\n",
    "    outputs=[\"text\"],\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
