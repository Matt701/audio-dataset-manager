{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working page leafthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def paginate(page, max_page, page_change):\n",
    "    new_page = page + page_change\n",
    "    new_page = max(1, new_page)  # Ensures page is not less than 1\n",
    "    new_page = min(new_page, max_page)  # Ensures page does not exceed max_page\n",
    "    return new_page\n",
    "\n",
    "def paginate_go(page, max_page):\n",
    "    try:\n",
    "        page = int(page)\n",
    "    except ValueError:\n",
    "        print(f'Invalid page number: {page}')\n",
    "        return None\n",
    "    return paginate(page, max_page, 0)\n",
    "def create_gradio_app():\n",
    "    with gr.Blocks() as app:\n",
    "        with gr.Row():\n",
    "            page_input = gr.Number(label=\"Page Number\", value=1)\n",
    "            max_page = gr.Number(label=\"Max Page\", value=10)  # Assuming max 10 pages for testing\n",
    "            go_button = gr.Button(\"Go to Page\")\n",
    "            next_button = gr.Button(\"Next\")\n",
    "            prev_button = gr.Button(\"Previous\")\n",
    "            current_page_label = gr.Label(\"Current Page: 1\")\n",
    "\n",
    "        def update_page_label(page):\n",
    "            current_page_label.update(f\"Current Page: {page}\")\n",
    "\n",
    "        go_button.click(fn=paginate_go, inputs=[page_input, max_page], outputs=page_input)\n",
    "        next_button.click(fn=lambda x, y: paginate(x, y, 1), inputs=[page_input, max_page], outputs=page_input)\n",
    "        prev_button.click(fn=lambda x, y: paginate(x, y, -1), inputs=[page_input, max_page], outputs=page_input)\n",
    "        page_input.change(update_page_label)\n",
    "\n",
    "    return app\n",
    "\n",
    "app = create_gradio_app()\n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working going through images across different pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import math\n",
    "import os\n",
    "\n",
    "IMAGES_TO_SHOW = 1  # Set to 1 since we're showing one audio file per page\n",
    "loaded_audios = []  # Global variable to store the loaded audios\n",
    "\n",
    "def paginate(page, max_page, page_change):\n",
    "    new_page = page + page_change\n",
    "    new_page = max(1, new_page)\n",
    "    new_page = min(new_page, max_page)\n",
    "    return new_page\n",
    "\n",
    "def get_audio_for_page(all_audios, page):\n",
    "    if 1 <= page <= len(all_audios):\n",
    "        return all_audios[page - 1]\n",
    "    return None  # Return None if the page is out of range\n",
    "\n",
    "def update_audio_display(page):\n",
    "    global loaded_audios\n",
    "    max_page = math.ceil(len(loaded_audios) / IMAGES_TO_SHOW)\n",
    "    displayed_audio = get_audio_for_page(loaded_audios, page)\n",
    "    audio_name = os.path.basename(displayed_audio) if displayed_audio else \"\"\n",
    "    current_page_label_text = f\"Current Page: {page}/{max_page}\"\n",
    "    return displayed_audio, audio_name, page, current_page_label_text\n",
    "\n",
    "def handle_pagination(page, delta):\n",
    "    global loaded_audios\n",
    "    max_page = math.ceil(len(loaded_audios) / IMAGES_TO_SHOW)\n",
    "    new_page = paginate(page, max_page, delta)\n",
    "    return update_audio_display(new_page)\n",
    "\n",
    "def handle_audio_load(audios):\n",
    "    global loaded_audios\n",
    "    loaded_audios = audios\n",
    "    return update_audio_display(1)  # Display first audio\n",
    "\n",
    "def create_gradio_app():\n",
    "    with gr.Blocks() as app:\n",
    "        with gr.Row():\n",
    "            audio_loader = gr.File(label=\"Load Audio Files\", file_count='multiple')\n",
    "            audio_player = gr.Audio(label=\"Audio Player\")\n",
    "            audio_name_box = gr.Textbox(label=\"Audio File Name\", interactive=True)\n",
    "\n",
    "        with gr.Row():\n",
    "            page_input = gr.Number(label=\"Page Number\", value=1, visible=True)\n",
    "            current_page_label = gr.Label(\"Current Page: 1/X\")\n",
    "            go_button = gr.Button(\"Go to Page\")\n",
    "            prev_button = gr.Button(\"Previous\")\n",
    "            next_button = gr.Button(\"Next\")\n",
    "\n",
    "        audio_loader.change(fn=handle_audio_load, inputs=[audio_loader], outputs=[audio_player, audio_name_box, page_input, current_page_label])\n",
    "        next_button.click(fn=lambda page: handle_pagination(page, 1), inputs=[page_input], outputs=[audio_player, audio_name_box, page_input, current_page_label])\n",
    "        prev_button.click(fn=lambda page: handle_pagination(page, -1), inputs=[page_input], outputs=[audio_player, audio_name_box, page_input, current_page_label])\n",
    "        go_button.click(fn=lambda page: update_audio_display(page), inputs=[page_input], outputs=[audio_player, audio_name_box, page_input, current_page_label])\n",
    "\n",
    "    return app\n",
    "\n",
    "app = create_gradio_app()\n",
    "app.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display audio files per page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import math\n",
    "import os\n",
    "\n",
    "IMAGES_TO_SHOW = 1  # Set to 1 since we're showing one audio file per page\n",
    "loaded_audios = []  # Global variable to store the loaded audios\n",
    "\n",
    "def paginate(page, max_page, page_change):\n",
    "    new_page = page + page_change\n",
    "    new_page = max(1, new_page)\n",
    "    new_page = min(new_page, max_page)\n",
    "    return new_page\n",
    "\n",
    "def get_audio_for_page(all_audios, page):\n",
    "    if 1 <= page <= len(all_audios):\n",
    "        return all_audios[page - 1]\n",
    "    return None  # Return None if the page is out of range\n",
    "\n",
    "def update_audio_display(page):\n",
    "    global loaded_audios\n",
    "    max_page = math.ceil(len(loaded_audios) / IMAGES_TO_SHOW)\n",
    "    displayed_audio = get_audio_for_page(loaded_audios, page)\n",
    "    audio_name = os.path.basename(displayed_audio) if displayed_audio else \"\"\n",
    "    current_page_label_text = f\"Current Page: {page}/{max_page}\"\n",
    "    return displayed_audio, audio_name, page, current_page_label_text\n",
    "\n",
    "def handle_pagination(page, delta):\n",
    "    global loaded_audios\n",
    "    max_page = math.ceil(len(loaded_audios) / IMAGES_TO_SHOW)\n",
    "    new_page = paginate(page, max_page, delta)\n",
    "    return update_audio_display(new_page)\n",
    "\n",
    "def handle_audio_load(audios):\n",
    "    global loaded_audios\n",
    "    loaded_audios = audios\n",
    "    return update_audio_display(1)  # Display first audio\n",
    "\n",
    "def create_gradio_app():\n",
    "    with gr.Blocks() as app:\n",
    "        with gr.Row():\n",
    "            audio_loader = gr.File(label=\"Load Audio Files\", file_count='multiple')\n",
    "            audio_player = gr.Audio(label=\"Audio Player\")\n",
    "            audio_name_box = gr.Textbox(label=\"Audio File Name\", interactive=True)\n",
    "\n",
    "        with gr.Row():\n",
    "            page_input = gr.Number(label=\"Page Number\", value=1, visible=True)\n",
    "            current_page_label = gr.Label(\"Current Page: 1/X\")\n",
    "            go_button = gr.Button(\"Go to Page\")\n",
    "            prev_button = gr.Button(\"Previous\")\n",
    "            next_button = gr.Button(\"Next\")\n",
    "\n",
    "        audio_loader.change(fn=handle_audio_load, inputs=[audio_loader], outputs=[audio_player, audio_name_box, page_input, current_page_label])\n",
    "        next_button.click(fn=lambda page: handle_pagination(page, 1), inputs=[page_input], outputs=[audio_player, audio_name_box, page_input, current_page_label])\n",
    "        prev_button.click(fn=lambda page: handle_pagination(page, -1), inputs=[page_input], outputs=[audio_player, audio_name_box, page_input, current_page_label])\n",
    "        go_button.click(fn=lambda page: update_audio_display(page), inputs=[page_input], outputs=[audio_player, audio_name_box, page_input, current_page_label])\n",
    "\n",
    "    return app\n",
    "\n",
    "app = create_gradio_app()\n",
    "app.launch()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplified script for managing one audio per page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import os\n",
    "\n",
    "def create_gradio_app():\n",
    "    loaded_audios = []  # Stores the loaded audio files\n",
    "\n",
    "    def change_audio(index):\n",
    "        if 0 <= index < len(loaded_audios):\n",
    "            audio_file = loaded_audios[index]\n",
    "            audio_name = os.path.basename(audio_file)\n",
    "            current_page_label = f\"Current Audio: {index + 1}/{len(loaded_audios)}\"\n",
    "            return audio_file, audio_name, index + 1, current_page_label\n",
    "        return None, \"\", 1, \"Audio not available\"\n",
    "\n",
    "    def next_audio(index):\n",
    "        return change_audio(index)\n",
    "\n",
    "    def prev_audio(index):\n",
    "        return change_audio(index - 2)\n",
    "\n",
    "    def load_audios(audios):\n",
    "        nonlocal loaded_audios\n",
    "        loaded_audios = audios\n",
    "        return change_audio(0)\n",
    "\n",
    "    with gr.Blocks() as app:\n",
    "        audio_loader = gr.File(label=\"Load Audio Files\", file_count='multiple')\n",
    "        audio_player = gr.Audio(label=\"Audio Player\")\n",
    "        audio_name_box = gr.Textbox(label=\"Audio File Name\", interactive=True)\n",
    "        page_input = gr.Number(label=\"Go to page:\", value=1, visible=True)\n",
    "        current_page_label = gr.Label(\"Current Audio: 1/X\")\n",
    "        next_button = gr.Button(\"Next\")\n",
    "        prev_button = gr.Button(\"Previous\")\n",
    "        go_button = gr.Button(\"Go to Page\")\n",
    "\n",
    "        audio_loader.change(fn=load_audios, inputs=[audio_loader], outputs=[audio_player, audio_name_box, page_input, current_page_label])\n",
    "        next_button.click(fn=lambda index: next_audio(index), inputs=[page_input], outputs=[audio_player, audio_name_box, page_input, current_page_label])\n",
    "        prev_button.click(fn=lambda index: prev_audio(index), inputs=[page_input], outputs=[audio_player, audio_name_box, page_input, current_page_label])\n",
    "        go_button.click(fn=lambda index: change_audio(index - 1), inputs=[page_input], outputs=[audio_player, audio_name_box, page_input, current_page_label])\n",
    "\n",
    "    return app\n",
    "\n",
    "app = create_gradio_app()\n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs and Outputs in Gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics of inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def change_textbox2():\n",
    "    return 'So what does a fine person like you do in a place such as this?'\n",
    "\n",
    "def change_textbox3():\n",
    "    return 'Yeah, I know. I love coding so much that I am still there at 10PM doing stuff like this instead of playing Elden Ring.'\n",
    "\n",
    "# The function change textboxes() is the function called by the go_button from the interface. The function itself can call other functions which will themselves\n",
    "# send variables or new components that we can then return to the UI. \n",
    "\n",
    "def change_textboxes(initial_text):\n",
    "    text1 = f'Oh so your name is {initial_text}! Nice to meet you!'\n",
    "    text2 = change_textbox2()\n",
    "    text3 = change_textbox3()\n",
    "\n",
    "    return text1, text2, text3\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    textbox1 = gr.Textbox(label='What is your name?')\n",
    "    textbox2 = gr.Textbox()\n",
    "    textbox3 = gr.Textbox()\n",
    "    go_button = gr.Button('Do your magic')\n",
    "    go_button.click(fn=change_textboxes, inputs=[textbox1], outputs=[textbox1, textbox2, textbox3])\n",
    "\n",
    "\n",
    "demo.launch()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the visibility of components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function that you call through a button can also send new gradio components that will automatically get mapped to the outputs defined in the UI (go_button.click), and thus replace them / update them. That is how you change the visibility of an element in Gradio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def change_textboxes(initial_text):\n",
    "    text1 = f'Oh so your name is {initial_text}! Nice to meet you!'\n",
    "    # Check if the user has entered a name\n",
    "    if initial_text.strip():\n",
    "        # Return visible textboxes with the respective messages\n",
    "        textbox2 = gr.Textbox(value='So what does a fine person like you do in a place such as this?', visible=True)\n",
    "        textbox3 = gr.Textbox(value='Yeah, I know. I love coding so much that I am still there at 10PM doing stuff like this instead of playing Elden Ring.', visible=True)\n",
    "    else:\n",
    "        # Return invisible textboxes\n",
    "        textbox2 = gr.Textbox(value='', visible=False)\n",
    "        textbox3 = gr.Textbox(value='', visible=False)\n",
    "    return text1, textbox2, textbox3\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    textbox1 = gr.Textbox(label='What is your name?')\n",
    "    go_button = gr.Button('Do your magic')\n",
    "\n",
    "    textbox2 = gr.Textbox(visible=False)  # Initially not visible\n",
    "    textbox3 = gr.Textbox(visible=False)  # Initially not visible\n",
    "\n",
    "    go_button.click(fn=change_textboxes, inputs=textbox1, outputs=[textbox1, textbox2, textbox3])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whisper and transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import json\n",
    "import os\n",
    "import torchaudio\n",
    "\n",
    "\n",
    "def transcribe_audio(audio_path, whisper_model):\n",
    "    audio_name = os.path.splitext(audio_path)[0]\n",
    "    model = whisper.load_model(whisper_model)\n",
    "    result = model.transcribe(audio_path)\n",
    "    return {audio_name: result}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "whisper_model = 'medium.en'\n",
    "audio_file =  r\"/home/maelys/AI_PROJECTS/SOUND/TOOLS/MRQ/ai-voice-cloning/training/train_mark_ultimate_8600/audio/But�_our_paths_soon_diverged_2_blood_guzzling.wav\"\n",
    "\n",
    "transcription = transcribe_audio(audio_file, whisper_model)\n",
    "\n",
    "json_file_path = \"json_test.json\"\n",
    "json_object = json.dumps(transcription, indent=4)\n",
    "\n",
    "with open (json_file_path, \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems I don't get exactly the same tokens or values as the MRQ ai-voice-cloning tool, although they are close. However, as I'm primarily building this tool to help me prepare datasets that I then will feed MRQ's tool, I find it hazardous to take the risk to botch the transcription of like thousands and thousand of audios, only to be compelled to do everything again in a few months. What I'm gonna do, then, is give a choice to the user of my tool. In the transcription tab, there will be a choice \"Transcribe here\" will launch and realize the transcribing internally with my tool. \"Transcribe with MRQ\" will make a textbox appear, describing the exact process to transcribe the audios through MRQ's tool, and then invite the user to go to the transcription check tab. In this last tab, the user will then simply point to the folder where the whisper.json has been created, whether internally or through MRQ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trasncribe panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7889\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7889/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "def internal_transcriber(input, model, export_path):\n",
    "    return gr.Textbox(label='Console output', value='This is WIP!', visible=True)\n",
    "\n",
    "def choose_transcriber(transcriber_choice):\n",
    "    if transcriber_choice == 'This tool':\n",
    "        internal_transcriber_group = gr.Group(visible=True)\n",
    "        mrq_tool_group = gr.Group(visible=False)\n",
    "    \n",
    "    else:\n",
    "        internal_transcriber_group = gr.Group(visible=False)\n",
    "        mrq_tool_group = gr.Group(visible=True)\n",
    "    \n",
    "    return internal_transcriber_group, mrq_tool_group\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    choice_radio = gr.Radio(label='Which tool do you want to use for transcribing?', choices=['This tool', 'MRQ ai-voice-cloning'])\n",
    "\n",
    "   \n",
    "    internal_transcriber_group = gr.Group(visible=False)\n",
    "    mrq_tool_group = gr.Group(visible=False)\n",
    "\n",
    "\n",
    "    with internal_transcriber_group:\n",
    "        input_folder = gr.Textbox(label='Path to the folder you want to transcribe')\n",
    "        model_choice = gr.Dropdown(label='Which Whisper model do you want to use?', \n",
    "                                            choices=[\"tiny\", \"tiny.en\", \"base\", \"base.en\", \"small\", \"small.en\", \n",
    "                                                    \"medium\", \"medium.en\",\n",
    "                                                    \"large\", \"large-v1\", \"large-v2\", ])\n",
    "        export_path = gr.Textbox(label='Path to the folder you want to export your transcribed json')\n",
    "        info_textbox = gr.Textbox(visible=False)\n",
    "        submit_button = gr.Button('Transcribe')\n",
    "    \n",
    "    with mrq_tool_group:\n",
    "        instructions_text = \"\"\"\n",
    "      \n",
    "                ># Hey there!\n",
    "     \n",
    "                >So you chose to use MRQ's ai-voice-cloning tool for your retranscription! Good choice, that tool is pure magic.\n",
    "\n",
    "                >Here's how to do this:\n",
    "\n",
    "                >>1. Go to MRQ ai-voice-cloning repo: [MRQ ai-voice-cloning](https://git.ecker.tech/mrq/ai-voice-cloning)\n",
    "                2. Clone the repo, install the tool (you have all instructions on the git page)\n",
    "                3. Put the voices you want to transcribe in a dedicated folder, inside the \"voices\" folder\n",
    "                4. Launch the interface (start.bat or start.sh depending on your OS)\n",
    "                5. Go to the \"Training\" tab\n",
    "                6. Choose your voice in \"Dataset Source\"\n",
    "                7. Click on Transcribe and Process\n",
    "                8. The \"whisper.json\" is written in the \"training\" folder, so go get the path\n",
    "                9. You're ready to go to the \"Checkout Transcription Tab\" here, point to the \"whisper.json\" file produced by MRQ ai-voice-cloning tool!\n",
    "                \n",
    "    \"\"\"\n",
    "        \n",
    "\n",
    "        \n",
    "        info_textbox = gr.Markdown(value = instructions_text)\n",
    "\n",
    "\n",
    "    choice_radio.change(fn=choose_transcriber, inputs=[choice_radio], outputs=[internal_transcriber_group, mrq_tool_group])\n",
    "    submit_button.click(fn=internal_transcriber, inputs=[input_folder, model_choice, export_path], outputs=[info_textbox])\n",
    "    \n",
    "\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
